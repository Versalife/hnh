---
title: "What Happens If ..."
date: 2023-08-25
type: sketch
---

... we row reduce the matrices of a neural network after training? If we replace the matrices
of the network with their row-reduced counterparts, does the network retain its performance?
Do we need to change the basis of the inputs to each layer in any fashion?

Recall that row reduction is an invertible operation that corresponds to left-multiplying a
matrix $M$ with elementary matrices: $\widetilde{M} = E_k \ldots E_1 M$.
