<html>

<head>
    <link rel="stylesheet" href="./styles.css" type="text/css">
</head>

<body class="vsc-initialized">
    <h1>Sketches and Snippets</h1>
    <section>
        <section class="citation featured">
            <div class="description">
                <h4>Interpreting Neural Networks using Graph Theory</h4>
                <h6><span class="conference cvpr">SKETCH</span> August 9, 2023 </h6>
                <!-- <h6><span class="conference cvpr">SKETCH</span></h6>
                <h5 datetime="2023-08-09">August 9, 2023</h5> -->
                <p>Neural Networks comprise of an ordered list of matrices with interspersed non-linear functions.
                    Every matrix is, in general, <a href="https://www.math3ma.com/blog/matrices-probability-graphs" target="_blank">equivalent to a weighted bipartite graph</a>.
                    Therefore, a neural network can be viewed as an ordered list of weighted bipartite graphs.
                    Can we use this correspondence to translate the tools developed in Graph Theory to aid our
                    understanding of Neural Networks? What does Ford-Fulkerson have to say about how information flows through a neural network?</p>
                <ul>
                    <li><a href="/vectorfusion/">[Website]</a></li>
                    <li><a href="/vectorfusion/gallery.html">[Gallery]</a></li>
                    <li><a href="https://arxiv.org/abs/2211.11319">[Paper]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation">
            <div class="description">
                <h4>On Maths, Birds, and Frogs</h4>
                <h5>Tai-Danae Bradley</h5>
                <h6><span class="conference workshop">SNIPPET</span> August13, 2023 </h6>
                <p>"... Rephrasing ideas in the precise language of mathematics allows
                    questions to be asked and answered in more useful, quantitative ways.
                    ... A bird's eye view of the landscape is a valuable perspective. 
                    It allows the observer to discover unexpected connections between different parts. 
                    However, in order to make those connections precise and rigorous, one requires the 
                    frogs attention to detail. One need to, as the frog does, frolic in the mud.
                </p>
                <ul>
                    <li><a href="/dreamfields/">[Website]</a></li>
                    <li><a href="https://arxiv.org/abs/2112.01455">[arXiv]</a></li>
                    <li><a href="https://www.youtube.com/watch?v=1Fke6w46tv4">[Overview video]</a></li>
                    <li><a href="https://github.com/google-research/google-research/tree/master/dreamfields">[Code]</a>
                    </li>
                    <li><a href="https://colab.research.google.com/drive/17GtPqdUCbG5CsmTnQFecPpoq_zpNKX7A?usp=sharing">[Colab
                            demo]</a></li>
                    <li><a href="/dreamfields/assets/dreamfields_cvpr_poster.pdf">[Poster]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation featured">
            <div class="description">
                <h4>Proving Theorems is an Exercise in Breadth First Search</h4>
                <h6><span class="conference cvpr">SKETCH</span> August 11, 2023 </h6>
                <p>Neural Networks comprise of an ordered list of matrices with interspersed non-linear functions.
                    Every matrix is, in general, <a href="https://www.math3ma.com/blog/matrices-probability-graphs" target="_blank">equivalent to a weighted bipartite graph</a>.
                    Therefore, a neural network can be viewed as an ordered list of weighted bipartite graphs.
                    Can we use this correspondence to translate the tools developed in Graph Theory to aid our
                    understanding of Neural Networks? What does Ford-Fulkerson have to say about how information flows through a neural network?</p>
                <ul>
                    <li><a href="/vectorfusion/">[Website]</a></li>
                    <li><a href="/vectorfusion/gallery.html">[Gallery]</a></li>
                    <li><a href="https://arxiv.org/abs/2211.11319">[Paper]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation featured" id="DDPM">
            <div class="description">
                <h4>On System Level Diseases</h4>
                <h6><span class="conference neurips">SKETCH</span> August 13, 2023</h6>
                <p>High-quality likelihood-based image generation; connect diffusion models to denoising score matching
                    and Langevin dynamics; compression, reconstruction and interpolation</p>
                <ul>
                    <li><a href="https://hojonathanho.github.io/diffusion/">[Website]</a></li>
                    <li><a href="https://arxiv.org/abs/2006.11239">[arXiv]</a></li>
                    <li><a href="https://slideslive.com/38936172">[Talk]</a></li>
                    <li><a href="images/diffusion_face_and_bedroom_video.mp4">[Sample video]</a></li>
                    <li><a href="https://github.com/hojonathanho/diffusion">[Code]</a></li>
                </ul>
            </div>
        </section>

    </section>

    <section>
        <section class="citation">
            <div class="description">
                <h4>Journey to the BAOAB-limit: finding effective MCMC samplers for score-based models</h4>
                <h5><b>Ajay Jain</b>*, Ben Poole*</h5>
                <h6><span class="conference workshop">Score-based Methods @ NeurIPS 2022</span></h6>
                <p>Sample diffusion models with a single noise level + high diversity.</p>
                <ul>
                    <li><a href="/journey/">[Website]</a></li>
                    <li><a
                            href="https://colab.research.google.com/drive/17kesyBVqubV_Zzchf2XoR-7MHk5jxTuo?usp=sharing">[Colab]</a>
                    </li>
                    <li><a href="https://github.com/ajayjain/journey-diffusion-samplers">[Code]</a></li>
                    <li><a
                            href="/journey/Journey to the BAOAB-limit finding effective MCMC samplers for score-based models.pdf">[Paper]</a>
                    </li>
                </ul>
            </div>
        </section>

        <section class="citation">
            <div class="description">
                <h4>Adaptive Categorical Discretization for Autoregressive Models</h4>
                <h5>Colin Li, <b>Ajay Jain</b>, Pieter Abbeel</h5>
                <h6><span class="conference uai">UAI 2022</span> Conference on Uncertainty in Artificial Intelligence
                </h6>
                <p>AdaCat learns expressive autoregressive models by capturing fine-grained variation in continuous
                    distributions with discrete density estimators.</p>
                <ul>
                    <li><a href="https://openreview.net/forum?id=HMzzPOLs9l5">[Paper]</a></li>
                    <li><a href="https://colinqiyangli.github.io/adacat/">[Website]</a></li>
                    <li><a href="https://github.com/ColinQiyangLi/AdaCat">[Code]</a></li>
                    <li><a href="/adacat/adacat_uai_poster.pdf">[Poster]</a></li>
                </ul>
        </section>

        <section class="citation">
            <div class="description">
                <h4>Contrastive Code Representation Learning</h4>
                <h5>Paras Jain*, <b>Ajay Jain</b>*, Tianjun Zhang, Pieter Abbeel, Joseph E. Gonzalez, Ion Stoica</h5>
                <h6><span class="conference emnlp">EMNLP 2021</span> Empirical Methods in Natural Language Processing
                </h6>
                <p>Learn to represent software functionality for automated software engineering tasks like type
                    inference, clone detection and summarization. Improving robustness of ML4Code.</p>
                <ul>
                    <li><a href="https://parasj.github.io/contracode/">[Website]</a></li>
                    <li><a href="https://aclanthology.org/2021.emnlp-main.482/">[ACL]</a></li>
                    <li><a href="https://arxiv.org/abs/2007.04973">[arXiv]</a></li>
                    <li><a href="https://ajayjain.github.io/assets/2021-contracode-poster-emnlp.pdf">[Poster]</a></li>
                    <li><a href="https://ajayjain.github.io/assets/2021.10.11-contracode-slides-emnlp.pdf">[Slides]</a>
                    </li>
                    <li><a href="https://www.youtube.com/watch?v=0deUDO6BqYY">[Talk]</a></li>
                    <li><a href="https://github.com/parasj/contracode/">[Code]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation">
            <div class="description">
                <h4>Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis</h4>
                <h5><b>Ajay Jain</b>, Matthew Tancik, Pieter Abbeel</h5>
                <h6><span class="conference iccv">ICCV 2021</span> International Conference on Computer Vision</h6>
                <p>CLIP + NeRF: Given only a few images of an object or scene, we reconstruct its 3D structure &amp;
                    render novel views using prior knowledge contained in large image encoders.</p>
                <ul>
                    <li><a href="/dietnerf/">[Website]</a></li>
                    <li><a href="https://arxiv.org/abs/2104.00677">[arXiv]</a></li>
                    <li><a href="https://github.com/ajayjain/DietNeRF/">[Code]</a></li>
                    <li><a href="https://www.youtube.com/watch?v=RF_3hsNizqw">[Overview video]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation" id="SGM">
            <div class="description">
                <h4>Sparse Graphical Memory for Robust Planning</h4>
                <h5>Scott Emmons*, <b>Ajay Jain</b>*, Michael Laskin*, Thanard Kurutach, Pieter Abbeel, Deepak Pathak
                </h5>
                <h6><span class="conference neurips">NeurIPS 2020</span> 34th Conference on Neural Information
                    Processing Systems</h6>
                <p>Provably robust+efficient long-horizon monocular navigation combining sparse graph planning and RL.
                    Propose two-way consistency to find landmark memories and create a topological map.</p>
                <ul>
                    <li><a href="https://mishalaskin.github.io/sgm/">[Website]</a></li>
                    <li><a href="https://arxiv.org/abs/2003.06417">[arXiv]</a></li>
                    <li><a
                            href="https://papers.nips.cc/paper/2020/hash/385822e359afa26d52b5b286226f2cea-Abstract.html">[NeurIPS]</a>
                    </li>
                    <li><a href="https://slideslive.com/38936447">[Talk]</a></li>
                    <li><a href="https://youtu.be/n3F3i7F3Lcg">[Video]</a></li>
                    <li><a href="https://github.io/ajayjain/assets/2020-sgm-poster-neurips.pdf">[Poster]</a></li>
                    <li><a href="https://github.com/scottemmons/sgm">[Code]</a></li>
                </ul>
            </div>
        </section>

        <section class="citation" id="LMConv">
            <div class="description">
                <h4>Locally Masked Convolution for Autoregressive Models</h4>
                <h5><b>Ajay Jain</b>, Pieter Abbeel, Deepak Pathak</h5>
                <h6><span class="conference uai">UAI 2020</span> 36th Conference on Uncertainty in Artificial
                    Intelligence</h6>
                <p>Outpainting with PixelCNNs. Our efficent op allows PixelCNNs to generate images in arbitrary orders.
                </p>
                <ul>
                    <li><a href="https://ajayjain.github.io/lmconv/">[Website]</a></li>
                    <li><a href="https://arxiv.org/abs/2006.12486">[arXiv]</a></li>
                    <li><a href="https://proceedings.mlr.press/v124/jain20b.html">[PMLR]</a></li>
                    <li><a href="https://www.youtube.com/watch?v=uGRRv3SExSs">[Talk]</a></li>
                    <li><a href="https://github.com/ajayjain/lmconv">[Code]</a></li>
                </ul>
            </div>

        </section>
    </section>
</body>

</html>